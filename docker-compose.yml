services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - agri

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      # Nội bộ 
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      # Listener cho giao tiếp bên ngoài Docker 
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    networks:
      - agri
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:29092", "--list"]
      interval: 10s
      timeout: 10s
      retries: 5

  mongodb:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - ./mongo_data:/data/db
    networks:
      - agri
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5

  simulator:
    build:
      context: .
      dockerfile: ./simulator/Dockerfile
    container_name: iot-simulator
    env_file: .env
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./.env:/app/.env
    user: root
    command: >
      sh -c "python /app/scripts/split_data.py && 
             python /app/scripts/iot_simulator.py"
    depends_on:
      - kafka
    networks: 
      - agri


  bridge:
    build:
      context: .
      dockerfile: ./bridge/Dockerfile
    container_name: mqtt-kafka-bridge
    env_file: .env 
    volumes:
      - ./scripts:/app/scripts
      - ./.env:/app/.env
    depends_on:
      kafka:
        condition: service_healthy 
    command: python /app/scripts/mqtt_kafka_bridge.py
    networks:
      - agri

  mqtt-alert-consumer:
    build:
      context: .
      dockerfile: ./bridge/Dockerfile
    container_name: mqtt-alert-consumer
    env_file: .env
    volumes:
      - ./scripts:/app/scripts
      - ./.env:/app/.env
    command: python /app/scripts/mqtt_alert_consumer.py
    networks:
      - agri
    restart: on-failure
  
  actuator-simulator:
    build:
      context: .
      dockerfile: ./bridge/Dockerfile
    container_name: actuator-simulator
    env_file: .env
    volumes:
      - ./scripts:/app/scripts
      - ./.env:/app/.env
    command: python /app/scripts/actuator_simulator.py
    networks:
      - agri
    restart: on-failure

  spark-eda:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    container_name: spark-eda
    env_file: .env
    environment:
      - SPARK_SCRIPT=spark_eda_windowing.py
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./scripts:/app/scripts
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      spark-master:
        condition: service_started
    networks:
      - agri

  spark-alert:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    container_name: spark-alert
    env_file: .env
    environment:
      - SPARK_SCRIPT=spark_alert_dashboard.py
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./scripts:/app/scripts
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      spark-master:
        condition: service_started
    networks:
      - agri
  
  spark-dashboard:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    container_name: kafka-dashboard
    env_file: .env
    environment:
      - SPARK_SCRIPT=kafka_grafana.py
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./scripts:/app/scripts
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      spark-master:
        condition: service_started
    networks:
      - agri

  spark-extract:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    environment:
      - SPARK_SCRIPT=Spark_App_Extract_datas.py
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./scripts:/app/scripts
    depends_on:
      - kafka
      - mongodb
    networks:
      - agri

  spark-model:
    build:
      context: .
      dockerfile: ./spark/Dockerfile.model
    ports:
      - "4040:4040"
    environment:
      - SPARK_SCRIPT=spark_app_prediction.py
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./models:/opt/bitnami/spark/models
    depends_on:
      - kafka
      - mongodb
      - spark-master
    networks:
      - agri

  spark-master:
    image: apache/spark:3.5.1-python3
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./models:/opt/bitnami/spark/models
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - agri

  spark-worker:
    image: apache/spark:3.5.1-python3
    build:
      context: .
      dockerfile: ./spark/Dockerfile.model
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./models:/opt/bitnami/spark/models
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    networks:
      - agri

  alert-consumer:
    build:
      context: .
      dockerfile: ./consumer/Dockerfile
    container_name: alert-consumer
    env_file: .env 
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - agri
    restart: on-failure 

  redis:
      image: "redis:alpine"
      container_name: redis
      ports:
        - "6379:6379"
      networks:
        - agri
      healthcheck:
        test: ["CMD", "redis-cli", "ping"]
        interval: 5s
        timeout: 3s
        retries: 5

  api-backend:
    build:
      context: .
      dockerfile: ./api/Dockerfile
    container_name: api-backend
    env_file: .env
    ports:
      - "8000:8000" 
    depends_on:
      redis:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    networks:
      - agri
    restart: on-failure

  dashboard:
    build:
      context: .
      dockerfile: ./dashboard/Dockerfile
    container_name: streamlit-dashboard
    env_file: .env 
    ports:
      - "8501:8501" 
    depends_on:
      - api-backend 
    networks:
      - agri
    restart: on-failure

  grafana:
    image: grafana/grafana:latest
    build:
      context: .
      dockerfile: ./grafana/Dockerfile
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - redis
    networks:
      - agri
    restart: always

networks:
  agri:
    driver: bridge
volumes:
  grafana-data: